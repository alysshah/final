<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <link rel="stylesheet" href="style_ind.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <title></title>
  </head>
  <body>

    <div class="navbar">
      <a href="index.html"><i class="fa fa-eye"></i></a>
      <a href="info.html">MORE INFO</a>
      <div class="dropdown">
        <button class="dropbtn">EXAMPLES <i class="fa fa-caret-down"></i></button>
        <div class="dropdown-content">
          <a href="youtube.html">YOUTUBE</a>
          <a href="facebook.html">FACEBOOK</a>
          <a href="google.html">GOOGLE</a>
        </div>
      </div>
    </div>

    <div class="title">
      <p>BEHIND <span>Youtube's</span> ALGORITHM...</p>
    </div>

    <!-- <hr> -->

    <div class="content">

      <!-- <div class="about">
        <div class="left-about">
          pic goes here.
        </div>
        <div class="right-about">
          This is a short about section on the platform. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
        </div>
      </div> -->

      <div class="stat">
        <div class="number">~ 70%</div>
        <p>of all watched videos on Youtube are recommended</p>
      </div>

      <div class="section">
        <div class="section-title">HOW DOES THE AI FUNCTION?</div>
        <p>The AI learns through trial and error in order to figure out what content a user is prone to clicking, and, once it has found a “template” or “solution” that works, it keeps pushing it. In it's most simple form, the goal is to predict which videos will catch the attention of the person viewing and try to keep them consuming as much content as they can consecutively.</p>
        <br>
        <br>
        <div class="section-title">RESULTS</div>
        <!-- <p> -->
          <ul>
            <li><b>Rabbit holes,</b></li>
              <ul>
                <li><i>Definition: used to refer to a bizarre, confusing, or nonsensical situation or environment, typically one from which it is difficult to extricate oneself. (Oxford Languages)</i></li>
                <li>While it might seem like you just happen to lose track of time while watching or that rabbit holes are just painfully acurate and universal memes, the truth is that Youtube had been deliberately designed so as to cause this to happen. This is not simply a coincidence but rather the result of a home page carefully crafted in order to maximize clicks, watch time, engagement, etc.</li>
              </ul>
            <br>
            <li><b>Filter bubbles & echo chambers,</b></li>
            <ul>
              <li><i>Filter bubble: term coined by the Internet activist Eli Pariser to refer to a state of intellectual isolation that can result from personalized searches when a website algorithm selectively guesses what information a user would like to see based on information about the user, such as location, past click-behavior and search history (Wikipedia: "Filter Bubble")</i></li>
              <li><i>Echo chamber: In discussions of news media, an echo chamber refers to situations in which beliefs are amplified or reinforced by communication and repetition inside a closed system and insulated from rebuttal (Wikipedia: "Echo chamber (media)")</i></li>
              <li>Since the algorithm is only looking to feed you content that you want to see, it automatically filters out videos that don't correspond. Consequently, you are sheltered from the rest of the world and stuck in a loop where your existing beliefs (misinformed or not) are constantly reaffirmed and repeated. This creates the illusion of a distorted reality.</li>
            </ul>
            <br>
            <li><b>Polarization of society,</b></li>
            <ul>
              <li>Numerous studies show that users' Youtube recommendations alter depending on their political affiliation (whether the content they view or accounts they interact leaning more towards a certain party/ideology) in accordance with filter bubbles and echo chambers, enhancing political polarization in the US political debate. This means that, to an unknown degree, the state of the US government and the results of the 2020 US elections, for example, would be affected by Youtube filter bubbles and echo chambers. While this could be considered to be a magnification of the situation concerning the Youtube algorithm, these results show that a computer system could possibly be responsible for altering the very fabric of democracy.</li>
              <li>According to Guillaume Chaslot, ex-Google software engineer who helped shape the Youtube algorithm from 2010-2013, in his article “How Algorithms Can Learn to Discredit ‘the Media’”, “any smart AI that optimizes engagement with itself will have a tendency to discourage engagement to other channels.”</li>
            </ul>
          </ul>
        <!-- </p> -->
      </div>

      <div class="quote">
        <blockquote>Standing at an Olympian remove from the content, platforms get to claim a neutrality they possess legally but not in actual practice: go on YouTube in private mode and see what the algorithm recommends for you—white supremacist videos, flat-earth conspiracy videos, wild rants about global warming being a hoax. Yet YouTube has convinced not just legislators and lawyers but even its own users that it somehow has less to do with its videos than traditional media companies have to do with their content.</blockquote>
        <p> - Adrian Daub, "What Tech Calls Thinking" </p>
      </div>

      <div class="section">
        <div class="section-title">WHAT DOES THIS MEAN?</div>
        <p>While this recommendation system was built to make money by keeping users engaged, the type of content they would be watching was not as well taken into consideration. It is concerning that users run the risk of getting stuck in echo chambers as well as the fact that the content they are exposed to leans towrds conspiracy theories and alt-right videos.</p>
        <br>
        <br>
        <div class="section-title">RESSOURCES</div>
        <p>
          <ul>
            <li><a href="https://wiki.digitalmethods.net/Dmi/WinterSchool2021FIterTube">Digital Methods Winter School and Data Sprint 2020. “FIlterTube: Investigating Echo Chambers, Filter Bubbles and Polarization on YouTube.”</a></li>
            <li><a href="https://guillaumechaslot.medium.com/how-algorithms-can-learn-to-discredit-the-media-d1360157c4fa">Chaslot, Guillaume. "How Algorithms Can Learn to Discredit 'the Media'."</a></li>
          </ul>
        </p>
      </div>

      <div class="quote">
        <blockquote>At YouTube, I was working on YouTube recommendations. It worries me that an algorithm that I worked on is actually increasing polarization in society. But from the point of view of watch time, this polarization is extremely efficient at keeping people online.</blockquote>
        <blockquote>The flat-Earth conspiracy theory was recommended hundreds of millions of times by the algorithm. It’s easy to think that it’s just a few stupid people who get convinced, but the algorithm is getting smarter and smarter every day. So, today, they are convincing the people that the Earth is flat, but tomorrow, they will be convincing you of something that’s false.</blockquote>
        <p> - Guillaume Chaslot, "The Social Dilemma" </p>
      </div>

    </div>


    <div class="footer">
      <a href="index.html">GO BACK TO HOME PAGE
        <i class="fa fa-arrow-circle-right"></i>
      </a>
    </div>

  </body>
</html>
